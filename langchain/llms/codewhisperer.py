import json
from typing import Any, Dict, List, Mapping, Optional

from pydantic import Extra, root_validator

from langchain.callbacks.manager import CallbackManagerForLLMRun
from langchain.llms.base import LLM
from langchain.llms.utils import enforce_stop_tokens


class CodeWhisperer(LLM):
    """LLM provider to invoke CodeWhisperer model."""

    client: Any  #: :meta private:

    class Config:
        """Configuration for this pydantic object."""

        extra = Extra.forbid

    @root_validator()
    def validate_environment(cls, values: Dict) -> Dict:
        """Validate that AWS credentials to and python package exists in environment."""

        # Skip creating new client if passed in constructor
        if values["client"] is not None:
            return values
        else:
            raise Exception("Need to provide codewhisperer client.")

        return values

    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        """Get the identifying parameters."""
        return {}

    @property
    def _llm_type(self) -> str:
        """Return type of llm."""
        return "amazon_codewhisperer"

    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
        **kwargs: Any,
    ) -> str:
        """Call out to Bedrock service model.

        Args:
            prompt: The prompt to pass into the model.
            stop: Optional list of stop words to use when generating.

        Returns:
            The string generated by the model.

        Example:
            .. code-block:: python

                response = se("Tell me a joke.")
        """

        try:
            file_context = {
                "filename": "blah.md",
                "leftFileContent": prompt,
                "rightFileContent": "",
                "programmingLanguage": {"languageName": "python"},
            }

            # if len(content) > 4200:
            #     print(f"GenerateRecommendations content may exceed token vector size: {len(content)}")

            response = self.client.generate_recommendations(fileContext=file_context)
            text = response['recommendations'][0]['content']
            request_id = response['ResponseMetadata']['RequestId']

        except Exception as e:
            raise ValueError(f"Error raised by codewhisperer service: {e}")

        if stop is not None:
            text = enforce_stop_tokens(text, stop)

        return text
